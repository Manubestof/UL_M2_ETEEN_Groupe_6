#!/usr/bin/env python
"""
Pipeline principal r√©vis√© - Analyse compl√®te de l'impact des catastrophes naturelles sur les exportations.

Ce script orchestre l'ensemble du pipeline d'analyse en respectant strictement la m√©thodologie
de l'article de r√©f√©rence et en utilisant uniquement les param√®tres centralis√©s dans config.json.
Toutes les √©tapes sont ind√©pendantes, configurables, et document√©es dans le README.
"""

import sys
import os
import subprocess
import time
import argparse
from pathlib import Path
from loguru import logger
import json

# Chargement de la configuration centralis√©e
CONFIG_PATH = Path(__file__).parent / "config.json"
with open(CONFIG_PATH, "r") as f:
    config = json.load(f)

USE_CACHE = config.get("USE_CACHE", True)
CLEAR_CACHE = config.get("CLEAR_CACHE", False)
DATA_DIR = Path(config.get("DATA_DIR", "data"))
CACHE_DIR = Path(config.get("CACHE_DIR", "cache"))
RESULTS_DIR = Path(config.get("RESULTS_DIR", "results"))
TABLES_DIR = Path(config.get("TABLES_DIR", "tables"))
EXCLUDED_ISO_CODES = config.get("EXCLUDED_ISO_CODES", [])
PERIODS = config.get("EXPORT_PERIODS", [])
DISASTER_TYPES = config.get("DISASTER_TYPES", [])

print("="*100)
print("   üö¶ PIPELINE CONFIGURATION   ")
print("="*100)
print(f"üóÇÔ∏è  DATA_DIR      : {DATA_DIR}")
print(f"üóÉÔ∏è  CACHE_DIR     : {CACHE_DIR}")
print(f"üìä RESULTS_DIR   : {RESULTS_DIR}")
print(f"üìë TABLES_DIR    : {TABLES_DIR}")
print(f"üóùÔ∏è  USE_CACHE     : {USE_CACHE}")
print(f"üßπ CLEAR_CACHE   : {CLEAR_CACHE}")
print(f"üìÜ EXPORT_PERIODS: {PERIODS}")
print(f"üå™Ô∏è  DISASTER_TYPES: {DISASTER_TYPES}")
print("üîí EXCLUDED_ISO_CODES:")
for i in range(0, len(EXCLUDED_ISO_CODES), 10):
    print("\t" + ", ".join(EXCLUDED_ISO_CODES[i:i+10]))
print("="*100 + "\n")

PIPELINE_STEPS = [
    ("01_collect_exports_data.py", "Collecte et nettoyage des exports (UN Comtrade)"),
    ("02_collect_disasters_data.py", "Collecte et pr√©paration des catastrophes (EM-DAT, GeoMet)"),
    ("03_validate_datasets.py", "Fusion, validation, cr√©ation des variables finales, datasets finaux"),
    ("04_econometric_analysis.R", "Analyse √©conom√©trique et g√©n√©ration des tables (LaTeX, CSV)")
]

PIPELINE_DIR = Path(__file__).parent

# Logging
logger.remove()
logger.add(sys.stderr, level=config.get("LOG_LEVEL", "INFO"))


def run_step(idx, step_file, description, rscript=False):
    logger.info(f"[STEP {idx+1}] {description}\n")
    script_path = PIPELINE_DIR / step_file
    if not script_path.exists():
        logger.error(f"Fichier manquant : {script_path}")
        return False
    cmd = ["Rscript", str(script_path)] if rscript else [sys.executable, str(script_path)]
    if step_file.endswith(".R"):
        cmd = ["Rscript", str(script_path)]
    try:
        result = subprocess.run(cmd, check=True)
        logger.success(f"‚úÖ √âtape termin√©e : {step_file}")
        print("="*100)
        return True
    except subprocess.CalledProcessError as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution de {step_file} : {e}")
        print("="*100)
        return False


def main():
    parser = argparse.ArgumentParser(description="Orchestrateur du pipeline complet")
    parser.add_argument("--step", type=int, help="Ex√©cuter une √©tape pr√©cise (1-4)")
    parser.add_argument("--clear_cache", action="store_true", help="Forcer le rafra√Æchissement du cache (si support√© par l'√©tape)")
    parser.add_argument("--fetch_missing", action="store_true", help="Forcer la r√©cup√©ration des ann√©es manquantes (si support√©)")
    args = parser.parse_args()

    # Ex√©cution d'une √©tape pr√©cise
    if args.step:
        idx = args.step - 1
        if idx < 0 or idx >= len(PIPELINE_STEPS):
            logger.error("Num√©ro d'√©tape invalide. Choisir entre 1 et 4.")
            sys.exit(1)
        step_file, description = PIPELINE_STEPS[idx]
        run_step(idx, step_file, description, rscript=step_file.endswith(".R"))
        return

    # Ex√©cution s√©quentielle de toutes les √©tapes
    for idx, (step_file, description) in enumerate(PIPELINE_STEPS):
        ok = run_step(idx, step_file, description, rscript=step_file.endswith(".R"))
        if not ok:
            logger.error(f"Arr√™t du pipeline √† l'√©tape {idx+1}.")
            sys.exit(1)
    logger.success("\nüéâ Pipeline complet ex√©cut√© avec succ√®s !")

if __name__ == "__main__":
    main()
